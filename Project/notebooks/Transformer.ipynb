{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os","execution_count":51,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install -q transformers > /dev/null\n!pip install -q clean-text > /dev/null\n!pip install torch-summary > /dev/null","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd, numpy as np\nimport torch\nimport torch.nn as nn\nfrom transformers import AutoConfig, AutoTokenizer, AutoModel, AdamW, get_linear_schedule_with_warmup\nfrom torch.optim import Adam\nfrom cleantext import clean\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split\nimport sklearn.metrics","execution_count":10,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Load the training dataset in a pandas dataframe**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_path = '../input/jigsaw-toxic-comment-classification-challenge/train.csv.zip'\ntrain = pd.read_csv(train_path)","execution_count":54,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Analyse the dataset**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.describe()","execution_count":52,"outputs":[{"output_type":"execute_result","execution_count":52,"data":{"text/plain":"               toxic   severe_toxic        obscene         threat  \\\ncount  159571.000000  159571.000000  159571.000000  159571.000000   \nmean        0.095844       0.009996       0.052948       0.002996   \nstd         0.294379       0.099477       0.223931       0.054650   \nmin         0.000000       0.000000       0.000000       0.000000   \n25%         0.000000       0.000000       0.000000       0.000000   \n50%         0.000000       0.000000       0.000000       0.000000   \n75%         0.000000       0.000000       0.000000       0.000000   \nmax         1.000000       1.000000       1.000000       1.000000   \n\n              insult  identity_hate  \ncount  159571.000000  159571.000000  \nmean        0.049364       0.008805  \nstd         0.216627       0.093420  \nmin         0.000000       0.000000  \n25%         0.000000       0.000000  \n50%         0.000000       0.000000  \n75%         0.000000       0.000000  \nmax         1.000000       1.000000  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>toxic</th>\n      <th>severe_toxic</th>\n      <th>obscene</th>\n      <th>threat</th>\n      <th>insult</th>\n      <th>identity_hate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>159571.000000</td>\n      <td>159571.000000</td>\n      <td>159571.000000</td>\n      <td>159571.000000</td>\n      <td>159571.000000</td>\n      <td>159571.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.095844</td>\n      <td>0.009996</td>\n      <td>0.052948</td>\n      <td>0.002996</td>\n      <td>0.049364</td>\n      <td>0.008805</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.294379</td>\n      <td>0.099477</td>\n      <td>0.223931</td>\n      <td>0.054650</td>\n      <td>0.216627</td>\n      <td>0.093420</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":53,"outputs":[{"output_type":"execute_result","execution_count":53,"data":{"text/plain":"                 id                                       comment_text  toxic  \\\n0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n\n   severe_toxic  obscene  threat  insult  identity_hate  \n0             0        0       0       0              0  \n1             0        0       0       0              0  \n2             0        0       0       0              0  \n3             0        0       0       0              0  \n4             0        0       0       0              0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>comment_text</th>\n      <th>toxic</th>\n      <th>severe_toxic</th>\n      <th>obscene</th>\n      <th>threat</th>\n      <th>insult</th>\n      <th>identity_hate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0000997932d777bf</td>\n      <td>Explanation\\nWhy the edits made under my usern...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000103f0d9cfb60f</td>\n      <td>D'aww! He matches this background colour I'm s...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>000113f07ec002fd</td>\n      <td>Hey man, I'm really not trying to edit war. It...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0001b41b1c6bb37e</td>\n      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0001d958c54c6e35</td>\n      <td>You, sir, are my hero. Any chance you remember...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.isnull().any()","execution_count":12,"outputs":[{"output_type":"execute_result","execution_count":12,"data":{"text/plain":"id               False\ncomment_text     False\ntoxic            False\nsevere_toxic     False\nobscene          False\nthreat           False\ninsult           False\nidentity_hate    False\ndtype: bool"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"**Define the output classes**"},{"metadata":{"trusted":true},"cell_type":"code","source":"classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\ny = train[classes].values","execution_count":13,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Perform dataset cleaning such as removing stop words, emojis, punctuations etc. using clean-text library**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def clean_string(s): return clean(s, no_line_breaks=True, no_urls=True, no_punct=True)","execution_count":14,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Custom Dataset loader**"},{"metadata":{"trusted":true},"cell_type":"code","source":"class MyData(torch.utils.data.Dataset):\n    def __init__(self, data, label_cols):\n        self.data = data\n        self.label_cols = label_cols\n\n    def __getitem__(self, item):\n        comment = clean_string(self.data.comment_text[item])\n        toxic = self.data.toxic[item]\n        severe_toxic = self.data.severe_toxic[item]\n        obscene = self.data.obscene[item]\n        threat = self.data.threat[item]\n        insult = self.data.insult[item]\n        identity_hate = self.data.identity_hate[item]\n#         return comment, torch.FloatTensor([toxic, severe_toxic, obscene, threat, insult, identity_hate])\n        return comment, torch.Tensor([toxic, severe_toxic, obscene, threat, insult, identity_hate])\n    \n    def __len__(self):\n        return len(self.data)","execution_count":15,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"label_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n# train['none'] = 1-train[label_cols].max(axis=1)\n# label_cols.append('none')\nCOMMENT = 'comment_text'\nlabel_cols.append(COMMENT)","execution_count":16,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Set device for PyTorch Training**"},{"metadata":{"trusted":true},"cell_type":"code","source":"gpu = 0\ndevice = torch.device(gpu if torch.cuda.is_available() else \"cpu\")\nif torch.cuda.is_available():\n    torch.cuda.set_device(gpu)\nprint(device)","execution_count":17,"outputs":[{"output_type":"stream","text":"cuda:0\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"**Model parameters and hyper-parameters**"},{"metadata":{"trusted":true},"cell_type":"code","source":"MAX_SEQ_LEN = 128\nBATCH_SIZE = 64*2\nWARMUP_STEPS = 4\nEPOCHS = 1\nLEARNING_RATE = 5e-3\nmodel_name = 'bert-base-uncased' #'google/electra-small-discriminator' 'gpt2'\nlstm_units = 50","execution_count":18,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Define the tokenizer** \n\nThis is dependent on the transformer model passed as input in model_name. Also specify the max sentence length after tokenizing.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"import transformers\ntokenizer = AutoTokenizer.from_pretrained(model_name, model_max_length=MAX_SEQ_LEN, do_lower_case=True, add_special_tokens=True,\n                                                max_length=MAX_SEQ_LEN, pad_to_max_length=True)\ntokenizer.add_special_tokens({'pad_token': '[PAD]'})","execution_count":19,"outputs":[{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"230858cb969c40f3bd9a6ddf3b1977f2"}},"metadata":{}},{"output_type":"stream","text":"\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c11102e13ff24597a6e006f56d8dbfc2"}},"metadata":{}},{"output_type":"stream","text":"\n","name":"stdout"},{"output_type":"execute_result","execution_count":19,"data":{"text/plain":"0"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"**Load the training data into torch Dataset and perform train-validation set split.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_set = MyData(train, label_cols)\ntrain_set, val_set = torch.utils.data.random_split(train_set, [int(0.9*len(train_set)), len(train_set)-int(0.9*len(train_set))] )\ntrain_set = torch.utils.data.DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\nval_set = torch.utils.data.DataLoader(val_set, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)","execution_count":20,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Define custom nn model**"},{"metadata":{"trusted":true},"cell_type":"code","source":"class AutoNet(nn.Module):\n  def __init__(self, seqLength=MAX_SEQ_LEN, numClasses=6, model_name=model_name, lstm_units=50):\n    super(AutoNet, self).__init__()\n    self.config = AutoConfig.from_pretrained(model_name, hidden_dropout_prob=0.2, attention_probs_dropout_prob=0.2)\n    self.config.output_hidden_states = False\n    self.model = AutoModel.from_pretrained(model_name, config=self.config)\n    for param in self.model.parameters():\n      param.requires_grad=False\n    if model_name=='google/electra-small-discriminator':\n        self.lstm = nn.LSTM(256, lstm_units, dropout=0.1,\n                        num_layers=1, bidirectional=True, batch_first=True, bias=False)\n    else:\n        self.lstm = nn.LSTM(768, lstm_units, dropout=0.1,\n                        num_layers=1, bidirectional=True, batch_first=True)\n    self.l1 = nn.Linear(lstm_units * 2, 50)\n    self.d1 = nn.Dropout(0.2)\n    self.l2 = nn.Linear(50, numClasses)\n    self.sigmoid = nn.Sigmoid()\n\n  def forward(self,input_ids, attention_mask):\n    x = self.model(input_ids, attention_mask=attention_mask)[0]\n    x, (hidden, cell) = self.lstm(x)\n    x,_ = torch.max(x, dim=1)\n    x = self.l1(x)\n    x = self.d1(x)\n    x = self.l2(x)\n    x = self.sigmoid(x)\n    return x","execution_count":21,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Initialize the model, optimizer and the loss function used.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = AutoNet()\nmodel = model.to(device)\nmodel.train()\noptimizer = Adam(model.parameters(), lr=LEARNING_RATE)\nloss_criteria = nn.BCELoss()\nloss_criteria = loss_criteria.to(device)","execution_count":23,"outputs":[{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df8a0877910a4b0ea1946c26deec9227"}},"metadata":{}},{"output_type":"stream","text":"\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:61: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n  \"num_layers={}\".format(dropout, num_layers))\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from torchsummary import summary\nprint(summary(model))","execution_count":24,"outputs":[{"output_type":"stream","text":"=================================================================\nLayer (type:depth-idx)                   Param #\n=================================================================\n├─BertModel: 1-1                         --\n|    └─BertEmbeddings: 2-1               --\n|    |    └─Embedding: 3-1               (23,440,896)\n|    |    └─Embedding: 3-2               (393,216)\n|    |    └─Embedding: 3-3               (1,536)\n|    |    └─LayerNorm: 3-4               (1,536)\n|    |    └─Dropout: 3-5                 --\n|    └─BertEncoder: 2-2                  --\n|    |    └─ModuleList: 3-6              (85,054,464)\n|    └─BertPooler: 2-3                   --\n|    |    └─Linear: 3-7                  (590,592)\n|    |    └─Tanh: 3-8                    --\n├─LSTM: 1-2                              328,000\n├─Linear: 1-3                            5,050\n├─Dropout: 1-4                           --\n├─Linear: 1-5                            306\n├─Sigmoid: 1-6                           --\n=================================================================\nTotal params: 109,815,596\nTrainable params: 333,356\nNon-trainable params: 109,482,240\n=================================================================\n=================================================================\nLayer (type:depth-idx)                   Param #\n=================================================================\n├─BertModel: 1-1                         --\n|    └─BertEmbeddings: 2-1               --\n|    |    └─Embedding: 3-1               (23,440,896)\n|    |    └─Embedding: 3-2               (393,216)\n|    |    └─Embedding: 3-3               (1,536)\n|    |    └─LayerNorm: 3-4               (1,536)\n|    |    └─Dropout: 3-5                 --\n|    └─BertEncoder: 2-2                  --\n|    |    └─ModuleList: 3-6              (85,054,464)\n|    └─BertPooler: 2-3                   --\n|    |    └─Linear: 3-7                  (590,592)\n|    |    └─Tanh: 3-8                    --\n├─LSTM: 1-2                              328,000\n├─Linear: 1-3                            5,050\n├─Dropout: 1-4                           --\n├─Linear: 1-5                            306\n├─Sigmoid: 1-6                           --\n=================================================================\nTotal params: 109,815,596\nTrainable params: 333,356\nNon-trainable params: 109,482,240\n=================================================================\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"**Training the Model**"},{"metadata":{"trusted":true},"cell_type":"code","source":"model.train()\nfrom tqdm.notebook import tqdm\nfor epoch in tqdm(range(EPOCHS)):\n  count = 0\n  total_loss =0 \n  model.train()\n  for i,data in enumerate(train_set):\n    optimizer.zero_grad()\n    enc = tokenizer.batch_encode_plus(list(data[0]), pad_to_max_length=True, max_length=MAX_SEQ_LEN, \n                                return_tensors='pt', add_special_tokens=True, return_attention_mask=True,\n                                return_token_type_ids=False, )\n    input_ids = enc['input_ids'].to(device)\n    attention_mask = enc['attention_mask'].to(device)\n    labels = torch.tensor(data[1]).to(device)\n    out = model(input_ids=input_ids, attention_mask=attention_mask)\n    loss = loss_criteria(out, labels)\n    loss.backward()\n    optimizer.step()\n    total_loss += loss.detach().data\n    if (i+1)%256==0:\n        print(f\"Epoch: {epoch}, batch: {i+1}, loss: {total_loss/(BATCH_SIZE)}\")\n        total_loss = 0\n  torch.save(model.state_dict(), f'{model_name}NetBCE_{epoch}.pt')\n\n  model.eval()\n  all_pred = []\n  all_gold = []\n  with torch.no_grad():\n      for i,data in enumerate(val_set):\n        enc = tokenizer.batch_encode_plus(list(data[0]), pad_to_max_length=True, max_length=MAX_SEQ_LEN, return_tensors='pt')\n        input_ids = enc['input_ids'].to(device)\n        attention_mask = enc['attention_mask'].to(device)\n        labels = torch.tensor(data[1]).to(device)\n        out = model(input_ids=input_ids, attention_mask=attention_mask)\n        all_pred.extend(1*(out>0.9).clone().detach().cpu().numpy())\n        all_gold.extend((labels.type(torch.LongTensor).detach().cpu().numpy()))\n\n  count=0\n  for i in range(len(all_gold)):\n    if (all_gold[i]==all_pred[i]).all():\n      count+=1\n  print(\"Validation accuracy:\", count/len(all_gold))","execution_count":43,"outputs":[{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"968f9de015d24ed398e703f418ff7669"}},"metadata":{}},{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  \n","name":"stderr"},{"output_type":"stream","text":"Epoch: 0, batch: 256, loss: 0.10895722359418869\nEpoch: 0, batch: 512, loss: 0.11123456805944443\nEpoch: 0, batch: 768, loss: 0.11127224564552307\nEpoch: 0, batch: 1024, loss: 0.10830515623092651\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","name":"stderr"},{"output_type":"stream","text":"Validation accuracy: 0.9091991477628776\n\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"**Code cell for demo and some error analysis**"},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_text = \"You are such an amazing person\"\nclean_txt = clean_string(sample_text)\nout1 = tokenizer.encode_plus(list(clean_txt), pad_to_max_length=True, max_length=MAX_SEQ_LEN, return_tensors='pt')\ninput_ids = out1['input_ids'].to(device)\nattention_mask = out1['attention_mask'].to(device)\nmodel.eval()\nwith torch.no_grad():\n    preds = model(input_ids=input_ids, attention_mask=attention_mask)\nprint(preds)","execution_count":44,"outputs":[{"output_type":"stream","text":"tensor([[0.1249, 0.0051, 0.0325, 0.0118, 0.0502, 0.0076]], device='cuda:0')\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\naccuracy_score(all_gold, all_pred)","execution_count":27,"outputs":[{"output_type":"execute_result","execution_count":27,"data":{"text/plain":"0.9072565484396541"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"**Load Test data, preprocess and analyse**"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_labels_path = '../input/jigsaw-toxic-comment-classification-challenge/test_labels.csv.zip'\ntest_labels = pd.read_csv(test_labels_path)","execution_count":45,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_labels = test_labels.replace(to_replace=-1,value=0)\ntest_labels.sample(20)","execution_count":46,"outputs":[{"output_type":"execute_result","execution_count":46,"data":{"text/plain":"                      id  toxic  severe_toxic  obscene  threat  insult  \\\n130079  d96a653932db1804      0             0        0       0       0   \n79187   8426e4aef1a856fb      0             0        0       0       0   \n55237   5be811149a5acb1e      0             0        0       0       0   \n91958   994ea229d0438f99      0             0        0       0       0   \n147191  f60c1082ee56b0ae      0             0        0       0       0   \n51712   55d5519dabb96d3c      1             0        1       0       1   \n124063  cf31575e00845e2e      0             0        0       0       0   \n85496   8e9eb9b80342d650      0             0        0       0       0   \n45089   4ac4bf0c55c922d2      0             0        0       0       0   \n152810  ff63cdbc6195fc5b      0             0        0       0       0   \n123990  cf0fb8117159ccce      0             0        0       0       0   \n7021    0bdba4f823690c7f      0             0        0       0       0   \n125752  d210aefe1ffbe1ab      0             0        0       0       0   \n87023   9133595c845fa6fb      0             0        0       0       0   \n107689  b3af1b7ee085c958      0             0        0       0       0   \n120239  c8c59b04593cdd83      0             0        0       0       0   \n13581   16da00ce530df98b      0             0        0       0       0   \n2604    0484c82feb280b50      0             0        0       0       0   \n39362   414e038414f8e96f      0             0        0       0       0   \n23285   26da97e98ab73ea1      0             0        0       0       0   \n\n        identity_hate  \n130079              0  \n79187               0  \n55237               0  \n91958               0  \n147191              0  \n51712               0  \n124063              0  \n85496               0  \n45089               0  \n152810              0  \n123990              0  \n7021                0  \n125752              0  \n87023               0  \n107689              0  \n120239              0  \n13581               0  \n2604                0  \n39362               0  \n23285               0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>toxic</th>\n      <th>severe_toxic</th>\n      <th>obscene</th>\n      <th>threat</th>\n      <th>insult</th>\n      <th>identity_hate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>130079</th>\n      <td>d96a653932db1804</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>79187</th>\n      <td>8426e4aef1a856fb</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>55237</th>\n      <td>5be811149a5acb1e</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>91958</th>\n      <td>994ea229d0438f99</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>147191</th>\n      <td>f60c1082ee56b0ae</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>51712</th>\n      <td>55d5519dabb96d3c</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>124063</th>\n      <td>cf31575e00845e2e</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>85496</th>\n      <td>8e9eb9b80342d650</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>45089</th>\n      <td>4ac4bf0c55c922d2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>152810</th>\n      <td>ff63cdbc6195fc5b</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>123990</th>\n      <td>cf0fb8117159ccce</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7021</th>\n      <td>0bdba4f823690c7f</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>125752</th>\n      <td>d210aefe1ffbe1ab</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>87023</th>\n      <td>9133595c845fa6fb</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>107689</th>\n      <td>b3af1b7ee085c958</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>120239</th>\n      <td>c8c59b04593cdd83</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>13581</th>\n      <td>16da00ce530df98b</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2604</th>\n      <td>0484c82feb280b50</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>39362</th>\n      <td>414e038414f8e96f</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>23285</th>\n      <td>26da97e98ab73ea1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv('/kaggle/input/jigsaw-toxic-comment-classification-challenge/test.csv.zip')\n\ntest_set = test.merge(test_labels, left_index=True, right_index=True)\ntest_set = test_set[[\"id_x\", \"comment_text\", \"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]]\ntest_set = test_set.reset_index(drop=True)\ntest_set = test_set.rename(columns={\"id_x\": \"id\"})\ntest_set.head()","execution_count":47,"outputs":[{"output_type":"execute_result","execution_count":47,"data":{"text/plain":"                 id                                       comment_text  toxic  \\\n0  00001cee341fdb12  Yo bitch Ja Rule is more succesful then you'll...      0   \n1  0000247867823ef7  == From RfC == \\n\\n The title is fine as it is...      0   \n2  00013b17ad220c46  \" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...      0   \n3  00017563c3f7919a  :If you have a look back at the source, the in...      0   \n4  00017695ad8997eb          I don't anonymously edit articles at all.      0   \n\n   severe_toxic  obscene  threat  insult  identity_hate  \n0             0        0       0       0              0  \n1             0        0       0       0              0  \n2             0        0       0       0              0  \n3             0        0       0       0              0  \n4             0        0       0       0              0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>comment_text</th>\n      <th>toxic</th>\n      <th>severe_toxic</th>\n      <th>obscene</th>\n      <th>threat</th>\n      <th>insult</th>\n      <th>identity_hate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>00001cee341fdb12</td>\n      <td>Yo bitch Ja Rule is more succesful then you'll...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0000247867823ef7</td>\n      <td>== From RfC == \\n\\n The title is fine as it is...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00013b17ad220c46</td>\n      <td>\" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>00017563c3f7919a</td>\n      <td>:If you have a look back at the source, the in...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>00017695ad8997eb</td>\n      <td>I don't anonymously edit articles at all.</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"**Perform test data cleaning and load into Dataloader**"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_set['comment_text'] = test_set['comment_text'].apply(clean_string)\nids = test_set['id']\ntest_set = MyData(test_set, classes)\ntest_set = torch.utils.data.DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)","execution_count":50,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Model evaluation**"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"model.eval()\nall_pred = []\nall_gold = []\nwith torch.no_grad():\n    for i,data in enumerate(test_set):\n        enc = tokenizer.batch_encode_plus(list(data[0]), pad_to_max_length=True, max_length=MAX_SEQ_LEN, return_tensors='pt')\n        input_ids = enc['input_ids'].to(device)\n        attention_mask = enc['attention_mask'].to(device)\n        labels = torch.tensor(data[1]).to(device)\n        out = model(input_ids=input_ids, attention_mask=attention_mask)\n        all_pred.extend(out.clone().detach().cpu().numpy())\n        all_gold.extend((labels.type(torch.LongTensor).detach().cpu().numpy()))\n","execution_count":49,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n  FutureWarning,\n","name":"stderr"},{"output_type":"error","ename":"TypeError","evalue":"new(): invalid data type 'str'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-49-3286e2b9680b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'attention_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m#         all_pred.extend(1*(out>0.9).clone().detach().cpu().numpy())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: new(): invalid data type 'str'"]}]},{"metadata":{},"cell_type":"markdown","source":"**Test performance with 0.98 as the threshold score**"},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy_score(all_gold, (np.array(all_pred) > 0.98))","execution_count":62,"outputs":[{"output_type":"execute_result","execution_count":62,"data":{"text/plain":"0.9454440991355672"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"**Create CSV file for Kaggle Submission**"},{"metadata":{"trusted":true},"cell_type":"code","source":"target_columns = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]","execution_count":36,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ids = pd.Series(ids)\ny_preds = pd.DataFrame(all_pred, columns=target_columns)\nfinal_submission = pd.concat([ids, y_preds], axis=1)\nfinal_submission.head()\nfinal_submission.to_csv('submission_bert_2_bce_epochs.csv', index=False)","execution_count":37,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}