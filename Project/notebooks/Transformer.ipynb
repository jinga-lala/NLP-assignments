{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q transformers > /dev/null\n",
    "!pip install -q clean-text > /dev/null\n",
    "!pip install torch-summary > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoConfig, AutoTokenizer, AutoModel, AdamW, get_linear_schedule_with_warmup\n",
    "from torch.optim import Adam\n",
    "from cleantext import clean\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the training dataset in a pandas dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = '../input/jigsaw-toxic-comment-classification-challenge/train.csv.zip'\n",
    "train = pd.read_csv(train_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analyse the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.095844</td>\n",
       "      <td>0.009996</td>\n",
       "      <td>0.052948</td>\n",
       "      <td>0.002996</td>\n",
       "      <td>0.049364</td>\n",
       "      <td>0.008805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.294379</td>\n",
       "      <td>0.099477</td>\n",
       "      <td>0.223931</td>\n",
       "      <td>0.054650</td>\n",
       "      <td>0.216627</td>\n",
       "      <td>0.093420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               toxic   severe_toxic        obscene         threat  \\\n",
       "count  159571.000000  159571.000000  159571.000000  159571.000000   \n",
       "mean        0.095844       0.009996       0.052948       0.002996   \n",
       "std         0.294379       0.099477       0.223931       0.054650   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       0.000000   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "              insult  identity_hate  \n",
       "count  159571.000000  159571.000000  \n",
       "mean        0.049364       0.008805  \n",
       "std         0.216627       0.093420  \n",
       "min         0.000000       0.000000  \n",
       "25%         0.000000       0.000000  \n",
       "50%         0.000000       0.000000  \n",
       "75%         0.000000       0.000000  \n",
       "max         1.000000       1.000000  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id               False\n",
       "comment_text     False\n",
       "toxic            False\n",
       "severe_toxic     False\n",
       "obscene          False\n",
       "threat           False\n",
       "insult           False\n",
       "identity_hate    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define the output classes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "y = train[classes].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Perform dataset cleaning such as removing stop words, emojis, punctuations etc. using clean-text library**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_string(s): return clean(s, no_line_breaks=True, no_urls=True, no_punct=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Custom Dataset loader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyData(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, label_cols):\n",
    "        self.data = data\n",
    "        self.label_cols = label_cols\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        comment = clean_string(self.data.comment_text[item])\n",
    "        toxic = self.data.toxic[item]\n",
    "        severe_toxic = self.data.severe_toxic[item]\n",
    "        obscene = self.data.obscene[item]\n",
    "        threat = self.data.threat[item]\n",
    "        insult = self.data.insult[item]\n",
    "        identity_hate = self.data.identity_hate[item]\n",
    "#         return comment, torch.FloatTensor([toxic, severe_toxic, obscene, threat, insult, identity_hate])\n",
    "        return comment, torch.Tensor([toxic, severe_toxic, obscene, threat, insult, identity_hate])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "COMMENT = 'comment_text'\n",
    "label_cols.append(COMMENT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set device for PyTorch Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "gpu = 0\n",
    "device = torch.device(gpu if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.set_device(gpu)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model parameters and hyper-parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQ_LEN = 128\n",
    "BATCH_SIZE = 64*2\n",
    "WARMUP_STEPS = 4\n",
    "EPOCHS = 1\n",
    "LEARNING_RATE = 5e-3\n",
    "model_name = 'bert-base-uncased' #'google/electra-small-discriminator' 'gpt2'\n",
    "lstm_units = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define the tokenizer** \n",
    "\n",
    "This is dependent on the transformer model passed as input in model_name. Also specify the max sentence length after tokenizing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "230858cb969c40f3bd9a6ddf3b1977f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c11102e13ff24597a6e006f56d8dbfc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, model_max_length=MAX_SEQ_LEN, do_lower_case=True, add_special_tokens=True,\n",
    "                                                max_length=MAX_SEQ_LEN, pad_to_max_length=True)\n",
    "tokenizer.add_special_tokens({'pad_token': '[PAD]'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the training data into torch Dataset and perform train-validation set split.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = MyData(train, label_cols)\n",
    "train_set, val_set = torch.utils.data.random_split(train_set, [int(0.9*len(train_set)), len(train_set)-int(0.9*len(train_set))] )\n",
    "train_set = torch.utils.data.DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "val_set = torch.utils.data.DataLoader(val_set, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define custom nn model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoNet(nn.Module):\n",
    "  def __init__(self, seqLength=MAX_SEQ_LEN, numClasses=6, model_name=model_name, lstm_units=50):\n",
    "    super(AutoNet, self).__init__()\n",
    "    self.config = AutoConfig.from_pretrained(model_name, hidden_dropout_prob=0.2, attention_probs_dropout_prob=0.2)\n",
    "    self.config.output_hidden_states = False\n",
    "    self.model = AutoModel.from_pretrained(model_name, config=self.config)\n",
    "    for param in self.model.parameters():\n",
    "      param.requires_grad=False\n",
    "    if model_name=='google/electra-small-discriminator':\n",
    "        self.lstm = nn.LSTM(256, lstm_units, dropout=0.1,\n",
    "                        num_layers=1, bidirectional=True, batch_first=True, bias=False)\n",
    "    else:\n",
    "        self.lstm = nn.LSTM(768, lstm_units, dropout=0.1,\n",
    "                        num_layers=1, bidirectional=True, batch_first=True)\n",
    "    self.l1 = nn.Linear(lstm_units * 2, 50)\n",
    "    self.d1 = nn.Dropout(0.2)\n",
    "    self.l2 = nn.Linear(50, numClasses)\n",
    "    self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "  def forward(self,input_ids, attention_mask):\n",
    "    x = self.model(input_ids, attention_mask=attention_mask)[0]\n",
    "    x, (hidden, cell) = self.lstm(x)\n",
    "    x,_ = torch.max(x, dim=1)\n",
    "    x = self.l1(x)\n",
    "    x = self.d1(x)\n",
    "    x = self.l2(x)\n",
    "    x = self.sigmoid(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initialize the model, optimizer and the loss function used.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df8a0877910a4b0ea1946c26deec9227",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:61: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    }
   ],
   "source": [
    "model = AutoNet()\n",
    "model = model.to(device)\n",
    "model.train()\n",
    "optimizer = Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "loss_criteria = nn.BCELoss()\n",
    "loss_criteria = loss_criteria.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "├─BertModel: 1-1                         --\n",
      "|    └─BertEmbeddings: 2-1               --\n",
      "|    |    └─Embedding: 3-1               (23,440,896)\n",
      "|    |    └─Embedding: 3-2               (393,216)\n",
      "|    |    └─Embedding: 3-3               (1,536)\n",
      "|    |    └─LayerNorm: 3-4               (1,536)\n",
      "|    |    └─Dropout: 3-5                 --\n",
      "|    └─BertEncoder: 2-2                  --\n",
      "|    |    └─ModuleList: 3-6              (85,054,464)\n",
      "|    └─BertPooler: 2-3                   --\n",
      "|    |    └─Linear: 3-7                  (590,592)\n",
      "|    |    └─Tanh: 3-8                    --\n",
      "├─LSTM: 1-2                              328,000\n",
      "├─Linear: 1-3                            5,050\n",
      "├─Dropout: 1-4                           --\n",
      "├─Linear: 1-5                            306\n",
      "├─Sigmoid: 1-6                           --\n",
      "=================================================================\n",
      "Total params: 109,815,596\n",
      "Trainable params: 333,356\n",
      "Non-trainable params: 109,482,240\n",
      "=================================================================\n",
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "├─BertModel: 1-1                         --\n",
      "|    └─BertEmbeddings: 2-1               --\n",
      "|    |    └─Embedding: 3-1               (23,440,896)\n",
      "|    |    └─Embedding: 3-2               (393,216)\n",
      "|    |    └─Embedding: 3-3               (1,536)\n",
      "|    |    └─LayerNorm: 3-4               (1,536)\n",
      "|    |    └─Dropout: 3-5                 --\n",
      "|    └─BertEncoder: 2-2                  --\n",
      "|    |    └─ModuleList: 3-6              (85,054,464)\n",
      "|    └─BertPooler: 2-3                   --\n",
      "|    |    └─Linear: 3-7                  (590,592)\n",
      "|    |    └─Tanh: 3-8                    --\n",
      "├─LSTM: 1-2                              328,000\n",
      "├─Linear: 1-3                            5,050\n",
      "├─Dropout: 1-4                           --\n",
      "├─Linear: 1-5                            306\n",
      "├─Sigmoid: 1-6                           --\n",
      "=================================================================\n",
      "Total params: 109,815,596\n",
      "Trainable params: 333,356\n",
      "Non-trainable params: 109,482,240\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "print(summary(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "968f9de015d24ed398e703f418ff7669",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, batch: 256, loss: 0.10895722359418869\n",
      "Epoch: 0, batch: 512, loss: 0.11123456805944443\n",
      "Epoch: 0, batch: 768, loss: 0.11127224564552307\n",
      "Epoch: 0, batch: 1024, loss: 0.10830515623092651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.9091991477628776\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "from tqdm.notebook import tqdm\n",
    "for epoch in tqdm(range(EPOCHS)):\n",
    "  count = 0\n",
    "  total_loss =0 \n",
    "  model.train()\n",
    "  for i,data in enumerate(train_set):\n",
    "    optimizer.zero_grad()\n",
    "    enc = tokenizer.batch_encode_plus(list(data[0]), pad_to_max_length=True, max_length=MAX_SEQ_LEN, \n",
    "                                return_tensors='pt', add_special_tokens=True, return_attention_mask=True,\n",
    "                                return_token_type_ids=False, )\n",
    "    input_ids = enc['input_ids'].to(device)\n",
    "    attention_mask = enc['attention_mask'].to(device)\n",
    "    labels = torch.tensor(data[1]).to(device)\n",
    "    out = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "    loss = loss_criteria(out, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    total_loss += loss.detach().data\n",
    "    if (i+1)%256==0:\n",
    "        print(f\"Epoch: {epoch}, batch: {i+1}, loss: {total_loss/(BATCH_SIZE)}\")\n",
    "        total_loss = 0\n",
    "  torch.save(model.state_dict(), f'{model_name}NetBCE_{epoch}.pt')\n",
    "\n",
    "  model.eval()\n",
    "  all_pred = []\n",
    "  all_gold = []\n",
    "  with torch.no_grad():\n",
    "      for i,data in enumerate(val_set):\n",
    "        enc = tokenizer.batch_encode_plus(list(data[0]), pad_to_max_length=True, max_length=MAX_SEQ_LEN, return_tensors='pt')\n",
    "        input_ids = enc['input_ids'].to(device)\n",
    "        attention_mask = enc['attention_mask'].to(device)\n",
    "        labels = torch.tensor(data[1]).to(device)\n",
    "        out = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        all_pred.extend(1*(out>0.9).clone().detach().cpu().numpy())\n",
    "        all_gold.extend((labels.type(torch.LongTensor).detach().cpu().numpy()))\n",
    "\n",
    "  count=0\n",
    "  for i in range(len(all_gold)):\n",
    "    if (all_gold[i]==all_pred[i]).all():\n",
    "      count+=1\n",
    "  print(\"Validation accuracy:\", count/len(all_gold))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Code cell for demo and some error analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1249, 0.0051, 0.0325, 0.0118, 0.0502, 0.0076]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "sample_text = \"You are such an amazing person\"\n",
    "clean_txt = clean_string(sample_text)\n",
    "out1 = tokenizer.encode_plus(list(clean_txt), pad_to_max_length=True, max_length=MAX_SEQ_LEN, return_tensors='pt')\n",
    "input_ids = out1['input_ids'].to(device)\n",
    "attention_mask = out1['attention_mask'].to(device)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    preds = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9072565484396541"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(all_gold, all_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Test data, preprocess and analyse**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels_path = '../input/jigsaw-toxic-comment-classification-challenge/test_labels.csv.zip'\n",
    "test_labels = pd.read_csv(test_labels_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>130079</th>\n",
       "      <td>d96a653932db1804</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79187</th>\n",
       "      <td>8426e4aef1a856fb</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55237</th>\n",
       "      <td>5be811149a5acb1e</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91958</th>\n",
       "      <td>994ea229d0438f99</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147191</th>\n",
       "      <td>f60c1082ee56b0ae</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51712</th>\n",
       "      <td>55d5519dabb96d3c</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124063</th>\n",
       "      <td>cf31575e00845e2e</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85496</th>\n",
       "      <td>8e9eb9b80342d650</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45089</th>\n",
       "      <td>4ac4bf0c55c922d2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152810</th>\n",
       "      <td>ff63cdbc6195fc5b</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123990</th>\n",
       "      <td>cf0fb8117159ccce</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7021</th>\n",
       "      <td>0bdba4f823690c7f</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125752</th>\n",
       "      <td>d210aefe1ffbe1ab</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87023</th>\n",
       "      <td>9133595c845fa6fb</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107689</th>\n",
       "      <td>b3af1b7ee085c958</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120239</th>\n",
       "      <td>c8c59b04593cdd83</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13581</th>\n",
       "      <td>16da00ce530df98b</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2604</th>\n",
       "      <td>0484c82feb280b50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39362</th>\n",
       "      <td>414e038414f8e96f</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23285</th>\n",
       "      <td>26da97e98ab73ea1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id  toxic  severe_toxic  obscene  threat  insult  \\\n",
       "130079  d96a653932db1804      0             0        0       0       0   \n",
       "79187   8426e4aef1a856fb      0             0        0       0       0   \n",
       "55237   5be811149a5acb1e      0             0        0       0       0   \n",
       "91958   994ea229d0438f99      0             0        0       0       0   \n",
       "147191  f60c1082ee56b0ae      0             0        0       0       0   \n",
       "51712   55d5519dabb96d3c      1             0        1       0       1   \n",
       "124063  cf31575e00845e2e      0             0        0       0       0   \n",
       "85496   8e9eb9b80342d650      0             0        0       0       0   \n",
       "45089   4ac4bf0c55c922d2      0             0        0       0       0   \n",
       "152810  ff63cdbc6195fc5b      0             0        0       0       0   \n",
       "123990  cf0fb8117159ccce      0             0        0       0       0   \n",
       "7021    0bdba4f823690c7f      0             0        0       0       0   \n",
       "125752  d210aefe1ffbe1ab      0             0        0       0       0   \n",
       "87023   9133595c845fa6fb      0             0        0       0       0   \n",
       "107689  b3af1b7ee085c958      0             0        0       0       0   \n",
       "120239  c8c59b04593cdd83      0             0        0       0       0   \n",
       "13581   16da00ce530df98b      0             0        0       0       0   \n",
       "2604    0484c82feb280b50      0             0        0       0       0   \n",
       "39362   414e038414f8e96f      0             0        0       0       0   \n",
       "23285   26da97e98ab73ea1      0             0        0       0       0   \n",
       "\n",
       "        identity_hate  \n",
       "130079              0  \n",
       "79187               0  \n",
       "55237               0  \n",
       "91958               0  \n",
       "147191              0  \n",
       "51712               0  \n",
       "124063              0  \n",
       "85496               0  \n",
       "45089               0  \n",
       "152810              0  \n",
       "123990              0  \n",
       "7021                0  \n",
       "125752              0  \n",
       "87023               0  \n",
       "107689              0  \n",
       "120239              0  \n",
       "13581               0  \n",
       "2604                0  \n",
       "39362               0  \n",
       "23285               0  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels = test_labels.replace(to_replace=-1,value=0)\n",
    "test_labels.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>Yo bitch Ja Rule is more succesful then you'll...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>== From RfC == \\n\\n The title is fine as it is...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>\" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>:If you have a look back at the source, the in...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>I don't anonymously edit articles at all.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  00001cee341fdb12  Yo bitch Ja Rule is more succesful then you'll...      0   \n",
       "1  0000247867823ef7  == From RfC == \\n\\n The title is fine as it is...      0   \n",
       "2  00013b17ad220c46  \" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...      0   \n",
       "3  00017563c3f7919a  :If you have a look back at the source, the in...      0   \n",
       "4  00017695ad8997eb          I don't anonymously edit articles at all.      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('/kaggle/input/jigsaw-toxic-comment-classification-challenge/test.csv.zip')\n",
    "\n",
    "test_set = test.merge(test_labels, left_index=True, right_index=True)\n",
    "test_set = test_set[[\"id_x\", \"comment_text\", \"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]]\n",
    "test_set = test_set.reset_index(drop=True)\n",
    "test_set = test_set.rename(columns={\"id_x\": \"id\"})\n",
    "test_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Perform test data cleaning and load into Dataloader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set['comment_text'] = test_set['comment_text'].apply(clean_string)\n",
    "ids = test_set['id']\n",
    "test_set = MyData(test_set, classes)\n",
    "test_set = torch.utils.data.DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "all_pred = []\n",
    "all_gold = []\n",
    "with torch.no_grad():\n",
    "    for i,data in enumerate(test_set):\n",
    "        enc = tokenizer.batch_encode_plus(list(data[0]), pad_to_max_length=True, max_length=MAX_SEQ_LEN, return_tensors='pt')\n",
    "        input_ids = enc['input_ids'].to(device)\n",
    "        attention_mask = enc['attention_mask'].to(device)\n",
    "        labels = torch.tensor(data[1]).to(device)\n",
    "        out = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        all_pred.extend(out.clone().detach().cpu().numpy())\n",
    "        all_gold.extend((labels.type(torch.LongTensor).detach().cpu().numpy()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test performance with 0.98 as the threshold score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9454440991355672"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(all_gold, (np.array(all_pred) > 0.98))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create CSV file for Kaggle Submission**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_columns = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = pd.Series(ids)\n",
    "y_preds = pd.DataFrame(all_pred, columns=target_columns)\n",
    "final_submission = pd.concat([ids, y_preds], axis=1)\n",
    "final_submission.head()\n",
    "final_submission.to_csv('submission_bert_2_bce_epochs.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
